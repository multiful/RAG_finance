"""Main FastAPI application with Phase A/B Architecture."""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from datetime import datetime

from app.core.config import settings
from app.api.routes import router as main_router
from app.api.advanced_routes import router as advanced_router
from app.api.pipeline_routes import router as pipeline_router


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan handler."""
    # Startup
    print(f"ğŸš€ Starting {settings.APP_NAME}")
    print(f"ğŸ“Š Phase A: Data Ingestion (LLM Ops)")
    print(f"ğŸ“Š Phase B: Serving Service (FastAPI + Redis)")
    print(f"ğŸ” LangSmith enabled: {bool(settings.LANGSMITH_API_KEY)}")
    print(f"ğŸ“„ LlamaParse enabled: {bool(settings.LLAMAPARSE_API_KEY)}")
    yield
    # Shutdown
    print(f"ğŸ‘‹ Shutting down {settings.APP_NAME}")


app = FastAPI(
    title=settings.APP_NAME,
    description="""
    # FSC Policy RAG System - Phase A/B Architecture
    
    ## Phase A: ë°ì´í„° ì¸ì œìŠ¤ì²œ (LLM Ops)
    - **Collector**: ê¸ˆìœµìœ„ RSS 1ì¼ 4íšŒ ì²´í¬
    - **Parser**: LlamaParse APIë¡œ PDF/HWP â†’ ë§ˆí¬ë‹¤ìš´ ë³€í™˜
    - **Chunker**: LangChainìœ¼ë¡œ ë¬¸ë§¥ ë³´ì¡´ ì²­í‚¹ + ì—…ê¶Œ ë©”íƒ€ë°ì´í„°
    - **Embedder**: OpenAIë¡œ ë²¡í„° ë³€í™˜ â†’ Supabase(pgvector)
    
    ## Phase B: ì„œë¹™ ì„œë¹„ìŠ¤ (FastAPI + Redis)
    - **Cache Layer**: Upstash Redisë¡œ ë™ì¼ ì§ˆë¬¸ ìºì‹±
    - **Reasoning**: LangGraph Agentë¡œ ì§ˆë¬¸ ìœ í˜• íŒë‹¨ + Query Expansion
    - **Retrieval**: Hybrid Search (BM25 + Vector)
    - **Reranker**: Cross-Encoderë¡œ Top-k ì¬ì •ë ¬
    - **Generation & Guardrail**: ê·¼ê±° ë¬¸ë‹¨ íƒœê·¸ + í™˜ê° ì²´í¬
    
    ## ê´€ì¸¡ì„± (Observability)
    - **LangSmith**: ë‹µë³€ ìƒì„± ì „ ê³¼ì • ì‹œê°í™”
    - **Ragas**: Groundedness ë“± ìˆ˜ì¹˜í™”ëœ í‰ê°€ ì§€í‘œ
    """,
    version="2.0.0",
    lifespan=lifespan
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(main_router, prefix=settings.API_V1_PREFIX)
app.include_router(advanced_router, prefix=f"{settings.API_V1_PREFIX}/advanced")
app.include_router(pipeline_router, prefix=f"{settings.API_V1_PREFIX}/pipeline")


@app.get("/")
async def root():
    """Root endpoint."""
    return {
        "name": settings.APP_NAME,
        "version": "2.0.0",
        "architecture": {
            "phase_a": "Data Ingestion (LLM Ops)",
            "phase_b": "Serving Service (FastAPI + Redis)",
            "observability": "LangSmith + Ragas"
        },
        "features": [
            "LangGraph Agent Workflow",
            "LlamaParse Document Parsing",
            "Ragas Evaluation",
            "LangSmith Observability",
            "Hybrid Vector Search (BM25 + Embedding)",
            "Cross-Encoder Reranking",
            "Guardrail & Hallucination Detection",
            "Redis Caching Layer"
        ],
        "docs": "/docs",
        "endpoints": {
            "main": f"{settings.API_V1_PREFIX}",
            "advanced": f"{settings.API_V1_PREFIX}/advanced",
            "pipeline": f"{settings.API_V1_PREFIX}/pipeline"
        }
    }


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "api": True,
            "langsmith": bool(settings.LANGSMITH_API_KEY),
            "llamaparse": bool(settings.LLAMAPARSE_API_KEY)
        },
        "phases": {
            "phase_a": "Data Ingestion Ready",
            "phase_b": "Serving Service Ready"
        }
    }
